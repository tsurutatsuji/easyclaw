# EasyClaw — 完全無料のローカルAIアシスタント

## なぜこれを作ろうと思ったのか

### きっかけ

Claude Code、Cursor、GitHub Copilot——いま最も強力なAIコーディングツールはどれもクラウドベースで、月額$20〜$200のサブスクリプションが必要です。

私はあるとき気づきました。**「AIを使うために、毎月お金を払い続ける世界は本当に正しいのか？」**と。

2024年からオープンソースLLMの進化は爆発的です。Llama 3、Qwen 2.5、DeepSeek R1——これらのモデルは、ローカルPCで十分に動く品質に到達しました。にもかかわらず、ほとんどの人はまだクラウドAPIに依存しています。その理由は単純で、**ローカルLLMを使いこなすためのUI/UXが整っていない**からです。

EasyClawは、この問題を解決するために生まれました。

### 3つの信念

1. **AIは水道のようなインフラであるべき** — 使うたびに課金されるのではなく、一度セットアップすれば無料で使い続けられるべき
2. **データは自分の手元にあるべき** — チャット履歴、コード、個人情報がクラウドに送信されない安心感
3. **複雑さはユーザーに見せるべきではない** — Ollamaのインストールさえすれば、あとはブラウザを開くだけ

---

## どういう人に使ってほしいか

### プライマリーターゲット

- **個人開発者・学生** — AIコーディングを使いたいが、月額サブスクに抵抗がある人
- **プライバシー重視の開発者** — 企業秘密や個人データをクラウドに送りたくない人
- **オフライン環境で作業する人** — 飛行機の中、セキュリティの厳しい社内ネットワーク

### セカンダリーターゲット

- **AIに興味があるが技術的なハードルを感じている人** — ターミナル操作なしでAIアシスタントが使える
- **教育現場** — 生徒にAIツールを使わせたいが、API費用やデータ漏洩の心配がある教師
- **発展途上国の開発者** — 安定したインターネット接続やクレジットカードがなくてもAIが使える

---

## ローカルAIが主流になる——世界のトレンド

### すでに起きている変化

世界的に、AIは「クラウドからローカルへ」というパラダイムシフトが進行しています。

**ハードウェアの民主化**
- Apple Silicon (M1〜M4) により、一般的なノートPCでも7B〜14Bパラメータのモデルが快適に動作
- NVIDIAのRTX 4060以上で、70Bクラスのモデルも実用的に
- NPU搭載PCの普及（Intel Core Ultra, Qualcomm Snapdragon X Elite）

**オープンソースLLMの急成長**
- Meta Llama 3.2 — ChatGPT 3.5レベルをローカルで実現
- Alibaba Qwen 2.5 Coder — コーディング特化で商用LLMに匹敵
- DeepSeek R1 — OpenAI o1レベルの推論能力をオープンソースで公開

**ローカルAIインフラの成熟**
- Ollama — ワンコマンドでLLMをローカル実行（500万+ダウンロード）
- llama.cpp — あらゆるハードウェアでLLMを動かす基盤技術
- Apple MLX — Apple Silicon最適化の推論エンジン

### なぜローカルが勝つのか

| 観点 | クラウドAI | ローカルAI |
|------|-----------|-----------|
| コスト | 月額$20〜$200 | 初期投資のみ（PC購入費） |
| プライバシー | データがサーバーに送信される | 一切外部に出ない |
| レイテンシ | ネットワーク依存 | ゼロレイテンシ |
| 可用性 | サーバーダウン・API制限あり | 24/7利用可能 |
| カスタマイズ | プロバイダーの制約内 | 完全に自由 |

唯一の弱点だった「品質」のギャップが、2024-2025年のオープンソースモデルの進化により急速に縮まっています。**2025年は「ローカルAI元年」**と言えるでしょう。

---

## EasyClawの概要

### ひとことで言うと

**「Ollama + OpenClaw で動く、完全無料のローカルAIアシスタント」**

ブラウザを開くだけで、チャット・コード生成・ブラウザ操作がすべてローカルで完結します。

### 主な機能

#### 1. 3モデル自動オーケストレーション
タスクに応じて最適なLLMを自動選択。ユーザーはモデルの存在を意識する必要がありません。

- **llama3.2** (2GB) → 日常会話・質問応答（高速）
- **qwen2.5-coder:7b** (4.7GB) → コード生成・ファイル操作
- **deepseek-r1:14b** (9GB) → 深い推論・分析・ブラウザ操作

#### 2. コーディングエージェント
「〜を作って」と頼むだけで、AIが自律的にプログラムを作成します。

- ファイル作成・編集・読取
- ディレクトリ一覧・コード検索
- コマンド実行（pip install、npm install等）
- ループ検出による無限ループ防止
- エラー自動分析と修復

#### 3. ブラウザエージェント
URLを送るだけで、AIがChromeを起動してWebページを操作・情報収集します。

#### 4. Claude Code風のUI/UX
- リアルタイムストリーミング
- エージェント進捗のステップ表示
- ワークスペースバー（git status表示）
- Markdown対応の美しいチャットUI

### 技術スタック

```
[ブラウザ] ←→ [Express Server :3000] ←→ [Ollama :11434]
                     ↕
             [OpenClaw Gateway :18789]
                     ↕
             [Chrome (Playwright)]
```

- **Backend**: Node.js, Express, SQLite
- **Frontend**: Vanilla JS (SPA), SSE streaming
- **LLM**: Ollama (完全ローカル)
- **Browser**: OpenClaw + Playwright

### セットアップ（5分で完了）

```bash
git clone https://github.com/tsurutatsuji/easyclaw.git
cd easyclaw && npm install
ollama pull llama3.2 && ollama pull qwen2.5-coder:7b && ollama pull deepseek-r1:14b
npm start
```

ブラウザで http://localhost:3000 を開くだけ。

---

## 今後のビジョン

EasyClawはまだ始まったばかりです。目指す世界は：

- **誰もがAIアシスタントを持てる世界** — 技術力や経済力に関係なく
- **プライバシーが当たり前の世界** — AIを使うために個人データを差し出さなくていい
- **AIがローカルで動く世界** — クラウドに依存しない、真に自律的なコンピューティング

> **"AI for everyone, owned by no one."**

---

GitHub: https://github.com/tsurutatsuji/easyclaw
